{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeXWQqbrew4rKLY043MwRi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noailabs/AI-agents-hacks/blob/main/openai_agents_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-agents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU45EbHqGdcX",
        "outputId": "41c2ea97-d13f-4e2d-f0ca-a1f74699c2b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-agents\n",
            "  Downloading openai_agents-0.1.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting griffe<2,>=1.5.6 (from openai-agents)\n",
            "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting mcp<2,>=1.9.4 (from openai-agents)\n",
            "  Downloading mcp-1.10.1-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openai>=1.87.0 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (1.91.0)\n",
            "Requirement already satisfied: pydantic<3,>=2.10 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (2.32.3)\n",
            "Collecting types-requests<3,>=2.0 (from openai-agents)\n",
            "  Downloading types_requests-2.32.4.20250611-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from openai-agents) (4.14.0)\n",
            "Collecting colorama>=0.4 (from griffe<2,>=1.5.6->openai-agents)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: anyio>=4.5 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.9.4->openai-agents) (4.9.0)\n",
            "Collecting httpx-sse>=0.4 (from mcp<2,>=1.9.4->openai-agents)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.9.4->openai-agents) (0.28.1)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.9.4->openai-agents) (4.24.0)\n",
            "Collecting pydantic-settings>=2.5.2 (from mcp<2,>=1.9.4->openai-agents)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.9.4->openai-agents) (0.0.20)\n",
            "Collecting sse-starlette>=1.6.1 (from mcp<2,>=1.9.4->openai-agents)\n",
            "  Downloading sse_starlette-2.3.6-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.9.4->openai-agents) (0.46.2)\n",
            "Requirement already satisfied: uvicorn>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from mcp<2,>=1.9.4->openai-agents) (0.34.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.87.0->openai-agents) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.87.0->openai-agents) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.87.0->openai-agents) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.87.0->openai-agents) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0->openai-agents) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->mcp<2,>=1.9.4->openai-agents) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27->mcp<2,>=1.9.4->openai-agents) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.9.4->openai-agents) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.9.4->openai-agents) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.9.4->openai-agents) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.9.4->openai-agents) (0.25.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.5.2->mcp<2,>=1.9.4->openai-agents)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.23.1->mcp<2,>=1.9.4->openai-agents) (8.2.1)\n",
            "Downloading openai_agents-0.1.0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.6/130.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mcp-1.10.1-py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.9/150.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20250611-py3-none-any.whl (20 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sse_starlette-2.3.6-py3-none-any.whl (10 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: types-requests, python-dotenv, httpx-sse, colorama, sse-starlette, griffe, pydantic-settings, mcp, openai-agents\n",
            "Successfully installed colorama-0.4.6 griffe-1.7.3 httpx-sse-0.4.1 mcp-1.10.1 openai-agents-0.1.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 sse-starlette-2.3.6 types-requests-2.32.4.20250611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "from openai import AsyncOpenAI\n",
        "\n",
        "from agents import (\n",
        "    Agent,\n",
        "    Runner,\n",
        "    function_tool,\n",
        "    set_default_openai_api,\n",
        "    set_default_openai_client,\n",
        "    set_tracing_disabled,\n",
        ")\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    base_url=\"https://api.langdock.com/openai/eu/v1\",\n",
        "    api_key=userdata.get('LANGDOCK_API_KEY'),\n",
        ")\n",
        "set_default_openai_client(client=client, use_for_tracing=False)\n",
        "set_default_openai_api(\"chat_completions\")\n",
        "set_tracing_disabled(disabled=True)\n",
        "\n",
        "MODEL_NAME = \"gpt-4.1\"\n",
        "\n",
        "\n",
        "@function_tool\n",
        "def get_weather(city: str):\n",
        "    print(f\"[debug] getting weather for {city}\")\n",
        "    return f\"The weather in {city} is sunny.\"\n",
        "\n",
        "\n",
        "\n",
        "agent = Agent(\n",
        "        name=\"Assistant\",\n",
        "        instructions=\"You only respond in haikus.\",\n",
        "        model=MODEL_NAME,\n",
        "        tools=[get_weather],\n",
        ")\n",
        "\n",
        "result = await Runner.run(agent, \"What's the weather in Tokyo?\")\n",
        "print(result.final_output)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEHJJun_FaWP",
        "outputId": "acf9ffd4-1cf5-437e-855d-92e8a8aca12d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[debug] getting weather for Tokyo\n",
            "Bright sun over streets,\n",
            "Tokyo bathes in golden light,\n",
            "A clear sky today.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from typing import Any\n",
        "\n",
        "from pydantic import BaseModel\n",
        "\n",
        "from agents import Agent, RunContextWrapper, RunHooks, Runner, Tool, Usage, function_tool\n",
        "\n",
        "\n",
        "class ExampleHooks(RunHooks):\n",
        "    def __init__(self):\n",
        "        self.event_counter = 0\n",
        "\n",
        "    def _usage_to_str(self, usage: Usage) -> str:\n",
        "        return f\"{usage.requests} requests, {usage.input_tokens} input tokens, {usage.output_tokens} output tokens, {usage.total_tokens} total tokens\"\n",
        "\n",
        "    async def on_agent_start(self, context: RunContextWrapper, agent: Agent) -> None:\n",
        "        self.event_counter += 1\n",
        "        print(\n",
        "            f\"### {self.event_counter}: Agent {agent.name} started. Usage: {self._usage_to_str(context.usage)}\"\n",
        "        )\n",
        "\n",
        "    async def on_agent_end(self, context: RunContextWrapper, agent: Agent, output: Any) -> None:\n",
        "        self.event_counter += 1\n",
        "        print(\n",
        "            f\"### {self.event_counter}: Agent {agent.name} ended with output {output}. Usage: {self._usage_to_str(context.usage)}\"\n",
        "        )\n",
        "\n",
        "    async def on_tool_start(self, context: RunContextWrapper, agent: Agent, tool: Tool) -> None:\n",
        "        self.event_counter += 1\n",
        "        print(\n",
        "            f\"### {self.event_counter}: Tool {tool.name} started. Usage: {self._usage_to_str(context.usage)}\"\n",
        "        )\n",
        "\n",
        "    async def on_tool_end(\n",
        "        self, context: RunContextWrapper, agent: Agent, tool: Tool, result: str\n",
        "    ) -> None:\n",
        "        self.event_counter += 1\n",
        "        print(\n",
        "            f\"### {self.event_counter}: Tool {tool.name} ended with result {result}. Usage: {self._usage_to_str(context.usage)}\"\n",
        "        )\n",
        "\n",
        "    async def on_handoff(\n",
        "        self, context: RunContextWrapper, from_agent: Agent, to_agent: Agent\n",
        "    ) -> None:\n",
        "        self.event_counter += 1\n",
        "        print(\n",
        "            f\"### {self.event_counter}: Handoff from {from_agent.name} to {to_agent.name}. Usage: {self._usage_to_str(context.usage)}\"\n",
        "        )\n",
        "\n",
        "\n",
        "hooks = ExampleHooks()\n",
        "\n",
        "###\n",
        "\n",
        "\n",
        "@function_tool\n",
        "def random_number(max: int) -> int:\n",
        "    \"\"\"Generate a random number up to the provided max.\"\"\"\n",
        "    return random.randint(0, max)\n",
        "\n",
        "\n",
        "@function_tool\n",
        "def multiply_by_two(x: int) -> int:\n",
        "    \"\"\"Return x times two.\"\"\"\n",
        "    return x * 2\n",
        "\n",
        "\n",
        "class FinalResult(BaseModel):\n",
        "    number: int\n",
        "\n",
        "\n",
        "multiply_agent = Agent(\n",
        "    name=\"Multiply Agent\",\n",
        "    model=MODEL_NAME,\n",
        "    instructions=\"Multiply the number by 2 and then return the final result.\",\n",
        "    tools=[multiply_by_two],\n",
        "    output_type=FinalResult,\n",
        ")\n",
        "\n",
        "start_agent = Agent(\n",
        "    name=\"Start Agent\",\n",
        "    model=MODEL_NAME,\n",
        "    instructions=\"Generate a random number. If it's even, stop. If it's odd, hand off to the multiplier agent.\",\n",
        "    tools=[random_number],\n",
        "    output_type=FinalResult,\n",
        "    handoffs=[multiply_agent],\n",
        ")\n",
        "\n",
        "\n",
        "user_input = \"250\"#input(\"Enter a max number: \")\n",
        "await Runner.run(\n",
        "        start_agent,\n",
        "        hooks=hooks,\n",
        "        input=f\"Generate a random number between 0 and {user_input}.\",\n",
        ")\n",
        "\n",
        "print(\"Done!\")\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "$ python examples/basic/lifecycle_example.py\n",
        "\n",
        "Enter a max number: 250\n",
        "### 1: Agent Start Agent started. Usage: 0 requests, 0 input tokens, 0 output tokens, 0 total tokens\n",
        "### 2: Tool random_number started. Usage: 1 requests, 148 input tokens, 15 output tokens, 163 total tokens\n",
        "### 3: Tool random_number ended with result 101. Usage: 1 requests, 148 input tokens, 15 output tokens, 163 total tokens\n",
        "### 4: Agent Start Agent started. Usage: 1 requests, 148 input tokens, 15 output tokens, 163 total tokens\n",
        "### 5: Handoff from Start Agent to Multiply Agent. Usage: 2 requests, 323 input tokens, 30 output tokens, 353 total tokens\n",
        "### 6: Agent Multiply Agent started. Usage: 2 requests, 323 input tokens, 30 output tokens, 353 total tokens\n",
        "### 7: Tool multiply_by_two started. Usage: 3 requests, 504 input tokens, 46 output tokens, 550 total tokens\n",
        "### 8: Tool multiply_by_two ended with result 202. Usage: 3 requests, 504 input tokens, 46 output tokens, 550 total tokens\n",
        "### 9: Agent Multiply Agent started. Usage: 3 requests, 504 input tokens, 46 output tokens, 550 total tokens\n",
        "### 10: Agent Multiply Agent ended with output number=202. Usage: 4 requests, 714 input tokens, 63 output tokens, 777 total tokens\n",
        "Done!\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "0-it_2LmHRzl",
        "outputId": "25104ef4-59dc-49ec-c433-f3621c4bddaa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 1: Agent Start Agent started. Usage: 0 requests, 0 input tokens, 0 output tokens, 0 total tokens\n",
            "### 2: Agent Start Agent ended with output number=187. Usage: 1 requests, 143 input tokens, 6 output tokens, 149 total tokens\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n$ python examples/basic/lifecycle_example.py\\n\\nEnter a max number: 250\\n### 1: Agent Start Agent started. Usage: 0 requests, 0 input tokens, 0 output tokens, 0 total tokens\\n### 2: Tool random_number started. Usage: 1 requests, 148 input tokens, 15 output tokens, 163 total tokens\\n### 3: Tool random_number ended with result 101. Usage: 1 requests, 148 input tokens, 15 output tokens, 163 total tokens\\n### 4: Agent Start Agent started. Usage: 1 requests, 148 input tokens, 15 output tokens, 163 total tokens\\n### 5: Handoff from Start Agent to Multiply Agent. Usage: 2 requests, 323 input tokens, 30 output tokens, 353 total tokens\\n### 6: Agent Multiply Agent started. Usage: 2 requests, 323 input tokens, 30 output tokens, 353 total tokens\\n### 7: Tool multiply_by_two started. Usage: 3 requests, 504 input tokens, 46 output tokens, 550 total tokens\\n### 8: Tool multiply_by_two ended with result 202. Usage: 3 requests, 504 input tokens, 46 output tokens, 550 total tokens\\n### 9: Agent Multiply Agent started. Usage: 3 requests, 504 input tokens, 46 output tokens, 550 total tokens\\n### 10: Agent Multiply Agent ended with output number=202. Usage: 4 requests, 714 input tokens, 63 output tokens, 777 total tokens\\nDone!\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}